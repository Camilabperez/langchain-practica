{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4759bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca00dd0",
   "metadata": {},
   "source": [
    "Gemini \n",
    "- 2.0 flash gratuita pero limitada\n",
    "anthropic(Claude) - gratuita pero limitada\n",
    "- \n",
    "OpenAI api paga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766ba15",
   "metadata": {},
   "source": [
    "# Componentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996be06",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6457805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about Python.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "promt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adejective} joke about {topic}.\"\n",
    ")\n",
    "\n",
    "promt_template.format(\n",
    "    adejective=\"funny\",\n",
    "    topic=\"Python\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdfe1d",
   "metadata": {},
   "source": [
    "## Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d66c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the Python say goodbye to the C++ programmer?\\n\\nBecause he didn't want to get bitten by a class!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = promt | llm\n",
    "chain.invoke({\"input\": \"Tell me a funny joke about Python.\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700e401",
   "metadata": {},
   "source": [
    "Branching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a242d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a message to escalate positive feedback to a human agent, designed to highlight the positive nature and encourage further action:\n",
      "\n",
      "**Option 1 (Short & Sweet):**\n",
      "\n",
      "> \"Escalating positive feedback for review. This customer had a great experience and we should consider sharing this success story/identifying what went well.\"\n",
      "\n",
      "**Option 2 (Slightly More Detailed):**\n",
      "\n",
      "> \"Escalating positive customer feedback. The customer reported [briefly mention the positive aspect, e.g., excellent service from agent X, loved the product feature Y].  Recommend reviewing for potential training opportunities or internal recognition.\"\n",
      "\n",
      "**Option 3 (Focus on Specific Action):**\n",
      "\n",
      "> \"Positive feedback received! Escalating to identify the agent/team responsible for [mention the positive outcome] so we can acknowledge their contribution and potentially replicate their success.\"\n",
      "\n",
      "**Key Considerations When Choosing:**\n",
      "\n",
      "*   **Your Internal Process:** How does your team typically handle positive feedback? Does it go to a specific manager, training department, or recognition program? Tailor the message to fit that flow.\n",
      "*   **The Specific Feedback:** The more specific you can be about *what* was positive, the better. It helps the human agent understand the context and take appropriate action.\n",
      "*   **Desired Outcome:** What do you *want* to happen with this positive feedback? Do you want to recognize an employee, improve training, or use it for marketing? Make that clear in your message.\n",
      "\n",
      "**Important Note:**  Make sure your system includes a way to easily access the original feedback when the agent receives the escalation.  A link to the transcript or a copy of the customer's message is essential.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableBranch\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "# Define prompt templates for different feedback types\n",
    "positive_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Generate a thank you note for this positive feedback: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "negative_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Generate a response addressing this negative feedback: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "neutral_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Generate a request for more details for this neutral feedback: {feedback}.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "escalate_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Generate a message to escalate this feedback to a human agent: {feedback}.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the feedback classification template\n",
    "classification_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\",\n",
    "         \"Classify the sentiment of this feedback as positive, negative, neutral, or escalate: {feedback}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the runnable branches for handling feedback\n",
    "branches = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"positive\" in x,\n",
    "        positive_feedback_template | model | StrOutputParser()  # Positive feedback chain\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"negative\" in x,\n",
    "        negative_feedback_template | model | StrOutputParser()  # Negative feedback chain\n",
    "    ),\n",
    "    (\n",
    "        lambda x: \"neutral\" in x,\n",
    "        neutral_feedback_template | model | StrOutputParser()  # Neutral feedback chain\n",
    "    ),\n",
    "    escalate_feedback_template | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create the classification chain\n",
    "classification_chain = classification_template | model | StrOutputParser()\n",
    "\n",
    "# Combine classification and response generation into one chain\n",
    "chain = classification_chain | branches\n",
    "\n",
    "# Run the chain with an example review\n",
    "# Good review - \"The product is excellent. I really enjoyed using it and found it very helpful.\"\n",
    "# Bad review - \"The product is terrible. It broke after just one use and the quality is very poor.\"\n",
    "# Neutral review - \"The product is okay. It works as expected but nothing exceptional.\"\n",
    "# Default - \"I'm not sure about the product yet. Can you tell me more about its features and benefits?\"\n",
    "\n",
    "review = \"he product is excellent. I really enjoyed using it and found it very helpful.\"\n",
    "result = chain.invoke({\"feedback\": review})\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd0ee9",
   "metadata": {},
   "source": [
    "## Memoria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41272fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Eres un asistente especializado en {abillity}. Puedes responder preguntas sobre {abillity}\"),  # Changed from set to tuple\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # Changed from set to tuple\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bdb45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    runnable=runnable,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Excelente elección! La ciencia de datos es un campo fascinante y en constante crecimiento. Para ayudarte a empezar, te propongo una hoja de ruta con los pasos clave y recursos útiles:\\n\\n**1. Fundamentos Matemáticos y Estadísticos:**\\n\\n*   **Álgebra Lineal:**\\n    *   Vectores, matrices, operaciones matriciales, autovalores y autovectores.\\n    *   **¿Por qué es importante?**  Modelos de machine learning, procesamiento de imágenes, reducción de dimensionalidad.\\n    *   **Recursos:**\\n        *   Khan Academy: Álgebra Lineal ([https://es.khanacademy.org/math/linear-algebra](https://es.khanacademy.org/math/linear-algebra))\\n        *   Libro: \"Linear Algebra and Its Applications\" de Gilbert Strang.\\n*   **Cálculo:**\\n    *   Derivadas, integrales, optimización.\\n    *   **¿Por qué es importante?**  Entender cómo funcionan los algoritmos de optimización en machine learning (descenso de gradiente).\\n    *   **Recursos:**\\n        *   Khan Academy: Cálculo ([https://es.khanacademy.org/math/calculus-home](https://es.khanacademy.org/math/calculus-home))\\n        *   Libro: \"Cálculo de una variable\" de Thomas Finney.\\n*   **Estadística y Probabilidad:**\\n    *   Estadística descriptiva, distribuciones de probabilidad, pruebas de hipótesis, regresión lineal.\\n    *   **¿Por qué es importante?**  Análisis exploratorio de datos, inferencia estadística, modelado predictivo.\\n    *   **Recursos:**\\n        *   Khan Academy: Estadística y Probabilidad ([https://es.khanacademy.org/math/statistics-probability](https://es.khanacademy.org/math/statistics-probability))\\n        *   Libro: \"Estadística para Administración y Economía\" de Levin & Rubin.\\n\\n**2. Programación:**\\n\\n*   **Python:**  El lenguaje más popular en ciencia de datos.\\n    *   **¿Qué aprender?**  Tipos de datos, estructuras de control, funciones, programación orientada a objetos, manejo de archivos.\\n    *   **Recursos:**\\n        *   Curso: \"Python para Todos\" de Charles Severance ([https://www.py4e.com/lessons](https://www.py4e.com/lessons))\\n        *   Codecademy: Learn Python 3 ([https://www.codecademy.com/learn/learn-python-3](https://www.codecademy.com/learn/learn-python-3))\\n        *   Documentación oficial de Python ([https://docs.python.org/3/](https://docs.python.org/3/))\\n*   **R:**  Otro lenguaje popular, especialmente en estadística.  (Opcional, pero recomendable si te interesa la estadística avanzada).\\n    *   **Recursos:**\\n        *   Codecademy: Learn R ([https://www.codecademy.com/learn/learn-r](https://www.codecademy.com/learn/learn-r))\\n        *   R for Data Science ([https://r4ds.hadley.nz/](https://r4ds.hadley.nz/))\\n\\n**3. Librerías Esenciales de Python:**\\n\\n*   **NumPy:**  Computación numérica eficiente con arrays multidimensionales.\\n    *   **¿Por qué es importante?**  Base para muchas otras librerías, operaciones matemáticas optimizadas.\\n    *   **Recursos:**\\n        *   Documentación oficial de NumPy ([https://numpy.org/doc/stable/](https://numpy.org/doc/stable/))\\n        *   Tutorial de NumPy en SciPy.org ([https://numpy.org/devdocs/user/absolute_beginners.html](https://numpy.org/devdocs/user/absolute_beginners.html))\\n*   **Pandas:**  Análisis y manipulación de datos con DataFrames.\\n    *   **¿Por qué es importante?**  Cargar, limpiar, transformar y analizar datos tabulares.\\n    *   **Recursos:**\\n        *   Documentación oficial de Pandas ([https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/))\\n        *   Tutorial de Pandas en la documentación oficial ([https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html))\\n*   **Matplotlib y Seaborn:**  Visualización de datos.\\n    *   **¿Por qué es importante?**  Crear gráficos para explorar datos y comunicar resultados.\\n    *   **Recursos:**\\n        *   Documentación oficial de Matplotlib ([https://matplotlib.org/stable/contents.html](https://matplotlib.org/stable/contents.html))\\n        *   Documentación oficial de Seaborn ([https://seaborn.pydata.org/](https://seaborn.pydata.org/))\\n        *   Galería de ejemplos de Matplotlib ([https://matplotlib.org/stable/gallery/index.html](https://matplotlib.org/stable/gallery/index.html))\\n        *   Galería de ejemplos de Seaborn ([https://seaborn.pydata.org/examples/index.html](https://seaborn.pydata.org/examples/index.html))\\n*   **Scikit-learn:**  Librería de machine learning.\\n    *   **¿Por qué es importante?**  Implementar algoritmos de clasificación, regresión, clustering, reducción de dimensionalidad, etc.\\n    *   **Recursos:**\\n        *   Documentación oficial de Scikit-learn ([https://scikit-learn.org/stable/](https://scikit-learn.org/stable/))\\n        *   Tutoriales de Scikit-learn ([https://scikit-learn.org/stable/tutorial/index.html](https://scikit-learn.org/stable/tutorial/index.html))\\n\\n**4. Machine Learning:**\\n\\n*   **Conceptos Fundamentales:**\\n    *   Aprendizaje supervisado (regresión, clasificación).\\n    *   Aprendizaje no supervisado (clustering, reducción de dimensionalidad).\\n    *   Evaluación de modelos (métricas, validación cruzada).\\n    *   Overfitting y underfitting.\\n*   **Algoritmos Clave:**\\n    *   Regresión lineal y logística.\\n    *   Árboles de decisión y Random Forests.\\n    *   Máquinas de Vectores de Soporte (SVM).\\n    *   K-Means Clustering.\\n    *   Reducción de dimensionalidad (PCA).\\n*   **Recursos:**\\n    *   Curso: \"Machine Learning\" de Andrew Ng en Coursera ([https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning))\\n    *   Libro: \"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" de Aurélien Géron.\\n    *   Documentación de Scikit-learn (¡imprescindible!).\\n\\n**5. Bases de Datos y SQL:**\\n\\n*   **SQL:**  Lenguaje para consultar y manipular bases de datos relacionales.\\n    *   **¿Por qué es importante?**  Extraer datos de bases de datos para análisis.\\n    *   **Recursos:**\\n        *   SQLZoo ([https://sqlzoo.net/](https://sqlzoo.net/))\\n        *   Khan Academy: SQL ([https://es.khanacademy.org/computing/computer-programming/sql](https://es.khanacademy.org/computing/computer-programming/sql))\\n*   **Bases de Datos NoSQL (Opcional):**  MongoDB, Cassandra, etc.  Útil para grandes volúmenes de datos no estructurados.\\n\\n**6. Visualización de Datos Avanzada (Opcional):**\\n\\n*   **Tableau o Power BI:**  Herramientas para crear dashboards interactivos.\\n*   **D3.js:**  Librería de JavaScript para visualizaciones personalizadas.\\n\\n**7. Big Data (Opcional):**\\n\\n*   **Hadoop y Spark:**  Frameworks para procesar grandes volúmenes de datos distribuidos.\\n\\n**8. Proyectos Prácticos:**\\n\\n*   **Kaggle:**  Participa en competiciones de ciencia de datos.  Es la mejor forma de aprender y construir un portafolio. ([https://www.kaggle.com/](https://www.kaggle.com/))\\n*   **Crea tus propios proyectos:**  Analiza datasets públicos, resuelve problemas de negocio simulados.\\n\\n**Consejos Adicionales:**\\n\\n*   **Aprende de forma activa:** No te limites a leer o ver videos.  ¡Escribe código, experimenta, comete errores!\\n*   **Únete a comunidades:**  Participa en foros, grupos de LinkedIn, meetups.  Comparte tus dudas y aprende de otros.\\n*   **Construye un portafolio:**  Muestra tus proyectos en GitHub o un blog personal.\\n*   **Mantente actualizado:**  La ciencia de datos evoluciona rápidamente.  Lee blogs, papers, sigue a expertos en redes sociales.\\n*   **No te frustres:**  El aprendizaje lleva tiempo.  Sé paciente y persistente.\\n\\n**Por dónde empezar:**\\n\\n1.  **Python:**  Empieza con un curso básico de Python.\\n2.  **NumPy y Pandas:**  Aprende a manipular datos con estas librerías.\\n3.  **Análisis Exploratorio de Datos (EDA):**  Practica con datasets públicos (Kaggle, UCI Machine Learning Repository).\\n4.  **Machine Learning Básico:**  Regresión lineal, clasificación con Scikit-learn.\\n5.  **¡Proyecto!**  Elige un proyecto que te interese y aplícalo.\\n\\n¡Mucha suerte en tu camino hacia la ciencia de datos!  Si tienes alguna pregunta más específica, no dudes en consultarme.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "        {\"abillity\":\"ciencia de datos\", \"input\":\"Quero aprender ciencia de dados.\"},\n",
    "        config={\"configurable\": {\"session_id\": \"12345\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e3b8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para empezar tu camino en la ciencia de datos, te sugiero seguir estos pasos iniciales:\\n\\n**1. Instala Python y un Entorno de Desarrollo:**\\n\\n*   **Instala Python:**\\n    *   Ve a la página oficial de Python: [https://www.python.org/downloads/](https://www.python.org/downloads/)\\n    *   Descarga la versión más reciente de Python 3 (por ejemplo, Python 3.12).\\n    *   Ejecuta el instalador y asegúrate de marcar la casilla \"Add Python to PATH\" (esto facilita el uso de Python desde la línea de comandos).\\n*   **Elige un Entorno de Desarrollo (IDE):**\\n    *   **Anaconda:**  Es una distribución de Python que incluye muchas librerías útiles para ciencia de datos (NumPy, Pandas, Scikit-learn, etc.) y un entorno llamado Jupyter Notebook, que es ideal para aprender y experimentar.  Descárgalo desde [https://www.anaconda.com/products/distribution](https://www.anaconda.com/products/distribution).\\n    *   **Visual Studio Code (VS Code):**  Es un editor de código muy popular y versátil.  Puedes instalar la extensión de Python para tener soporte para Python.  Descárgalo desde [https://code.visualstudio.com/](https://code.visualstudio.com/).\\n    *   **Google Colab:**  Es un entorno de Jupyter Notebook que se ejecuta en la nube.  Es muy útil si no quieres instalar nada en tu computadora.  Accede a él desde [https://colab.research.google.com/](https://colab.research.google.com/).\\n\\n**Recomendación:** Para empezar, te recomiendo **Anaconda** porque ya viene con todo lo que necesitas y Jupyter Notebook es muy amigable para aprender.\\n\\n**2. Aprende los Fundamentos de Python:**\\n\\n*   **Variables y Tipos de Datos:**  Aprende sobre números, strings, booleanos, listas, diccionarios, etc.\\n*   **Operadores:**  Aritméticos, de comparación, lógicos.\\n*   **Estructuras de Control:**  `if`, `else`, `for`, `while`.\\n*   **Funciones:**  Cómo definir y llamar funciones.\\n*   **Módulos:**  Cómo importar y usar módulos (librerías).\\n\\n**Recursos:**\\n\\n*   **\"Python para Todos\" de Charles Severance:**  Un excelente curso para principiantes.  Está disponible en español: [https://www.py4e.com/lessons](https://www.py4e.com/lessons)\\n*   **Codecademy: Learn Python 3:**  Un curso interactivo para aprender Python. [https://www.codecademy.com/learn/learn-python-3](https://www.codecademy.com/learn/learn-python-3)\\n\\n**Ejemplo Sencillo en Python (usando Jupyter Notebook):**\\n\\n1.  Abre Jupyter Notebook (si instalaste Anaconda, busca \"Jupyter Notebook\" en el menú de inicio).\\n2.  Crea un nuevo notebook (File -> New Notebook -> Python 3).\\n3.  Escribe el siguiente código en una celda y ejecútala (presiona Shift + Enter):\\n\\n```python\\n# Esto es un comentario\\nnombre = \"Juan\"\\nedad = 30\\nprint(f\"Hola, mi nombre es {nombre} y tengo {edad} años.\")\\n\\nnumeros = [1, 2, 3, 4, 5]\\nfor numero in numeros:\\n    print(numero * 2)\\n```\\n\\n**3. Instala y Aprende NumPy y Pandas:**\\n\\n*   **Instala NumPy y Pandas:**  Si usaste Anaconda, ya están instaladas.  Si no, puedes instalarlas con `pip` (el gestor de paquetes de Python):\\n\\n    ```bash\\n    pip install numpy pandas\\n    ```\\n\\n*   **Aprende NumPy:**  Cómo crear y manipular arrays.\\n*   **Aprende Pandas:**  Cómo crear y manipular DataFrames (tablas de datos).\\n\\n**Recursos:**\\n\\n*   **Documentación oficial de NumPy:** [https://numpy.org/doc/stable/](https://numpy.org/doc/stable/)\\n*   **Documentación oficial de Pandas:** [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)\\n*   **Tutorial de Pandas en la documentación oficial:** [https://pandas.pydata.org/docs/user_guide/10min.html](https://pandas.pydata.org/docs/user_guide/10min.html)\\n\\n**Ejemplo Sencillo con NumPy y Pandas (en Jupyter Notebook):**\\n\\n```python\\nimport numpy as np\\nimport pandas as pd\\n\\n# Crear un array NumPy\\narray_numpy = np.array([1, 2, 3, 4, 5])\\nprint(\"Array NumPy:\", array_numpy)\\n\\n# Crear un DataFrame de Pandas\\ndata = {\\'Nombre\\': [\\'Ana\\', \\'Pedro\\', \\'Maria\\'],\\n        \\'Edad\\': [25, 30, 28],\\n        \\'Ciudad\\': [\\'Madrid\\', \\'Barcelona\\', \\'Valencia\\']}\\ndf = pd.DataFrame(data)\\nprint(\"\\\\nDataFrame de Pandas:\")\\nprint(df)\\n\\n# Acceder a una columna del DataFrame\\nprint(\"\\\\nColumna \\'Edad\\':\")\\nprint(df[\\'Edad\\'])\\n```\\n\\n**4. Practica con un Dataset:**\\n\\n*   Descarga un dataset público de Kaggle ([https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)) o del UCI Machine Learning Repository ([http://archive.ics.uci.edu/ml/index.php](http://archive.ics.uci.edu/ml/index.php)).  Busca uno que te interese y que no sea demasiado grande para empezar.\\n*   Carga el dataset en un DataFrame de Pandas.\\n*   Explora los datos:\\n    *   Usa `df.head()`, `df.tail()`, `df.info()`, `df.describe()` para entender la estructura y el contenido del dataset.\\n    *   Calcula estadísticas descriptivas (media, mediana, desviación estándar, etc.).\\n    *   Crea gráficos sencillos (histogramas, diagramas de dispersión) con Matplotlib o Seaborn.\\n\\n**5. ¡No te Rindas!**\\n\\n*   Aprender ciencia de datos lleva tiempo y esfuerzo.  No te frustres si al principio te sientes abrumado.\\n*   Practica regularmente.  Cuanto más practiques, más rápido aprenderás.\\n*   Busca ayuda cuando la necesites.  Hay muchas comunidades online donde puedes hacer preguntas y obtener respuestas.\\n\\n¡Este es solo el comienzo!  Una vez que te sientas cómodo con los fundamentos de Python, NumPy y Pandas, puedes empezar a explorar temas más avanzados como machine learning, visualización de datos y bases de datos.  ¡Mucha suerte!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "        {\"abillity\":\"ciencia de datos\", \"input\":\"Como?\"},\n",
    "        config={\"configurable\": {\"session_id\": \"12345\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3645d20a",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b61610",
   "metadata": {},
   "source": [
    "Solo tiene procesado hasta lo que se entreno, por lo que se pueden usar tools para buscar informacion en otras fuentes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b5fcf",
   "metadata": {},
   "source": [
    "### Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f7d7472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de herramienta: wikipedia\n",
      "Descripción: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "Argumentos: {'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper()\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(\"Nombre de herramienta:\", wiki_tool.name) \n",
    "print(\"Descripción:\", wiki_tool.description) \n",
    "print(\"Argumentos:\", wiki_tool.args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a93d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Intelligent agent\\nSummary: In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. Leading AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\\nA specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.\\nIntelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.\\nIntelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior. Similarly, an evolutionary algorithm\\'s behavior is guided by a fitness function.\\nIntelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\\nIntelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".\\n\\n\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) models like large language models (LLMs) integrate and share data with external tools, systems, and data sources. Technology writers have dubbed MCP “the USB-C of AI apps”, underscoring its goal of serving as a universal connector between language-model agents and external software. Designed to standardize context exchange between AI assistants and software environments, MCP provides a model-agnostic universal interface for reading files, executing functions, and handling contextual prompts. It was officially announced and open-sourced by Anthropic in November 2024, and was adopted by major AI providers including OpenAI and Google DeepMind.\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run(\"LangChain\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803e3b8",
   "metadata": {},
   "source": [
    "### Servicio Tavily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43efc9",
   "metadata": {},
   "source": [
    "https://app.tavily.com/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0573f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '¿Qué es LangChain? - Google Cloud',\n",
       "  'url': 'https://cloud.google.com/use-cases/langchain?hl=es-419',\n",
       "  'content': '# ¿Qué es LangChain?\\n\\nLangChain es una plataforma de lenguaje de programación que permite a los desarrolladores construir y conectar modelos para acceder, transformar y compartir datos sin problemas. Ofrece un entorno potente y versátil para el desarrollo de modelos, lo que permite la manipulación de estructuras de datos, la encadenación de modelos y la incorporación de agentes externos como LaMDA. [...] En su núcleo, LangChain aprovecha una arquitectura distribuida que permite un procesamiento eficiente y escalable de datos de lenguaje. Emplea un diseño basado en microservicios, en el que cada cadena se ejecuta como un servicio independiente, lo que facilita la implementación y administración flexibles. Esta arquitectura permite una integración continua con servicios externos, incluidos los LLM y las fuentes de datos basadas en la nube. [...] LangChain funciona según el principio de la modularidad, que descompone los sistemas de IA basados en el lenguaje en componentes reutilizables. Estos componentes, conocidos como “cadenas”, encapsulan funcionalidades específicas, como la recuperación de datos, la interacción del modelo y la administración de la memoria. Al ensamblar estas cadenas en varias configuraciones, los desarrolladores pueden adaptar LangChain para cumplir con los requisitos únicos de sus aplicaciones.',\n",
       "  'score': 0.9537642},\n",
       " {'title': '¿Qué es LangChain? - IBM',\n",
       "  'url': 'https://www.ibm.com/es-es/think/topics/langchain',\n",
       "  'content': 'LangChain es un marco de orquestación de código abierto para el desarrollo de aplicaciones que utilizan [modelos de lenguaje de gran tamaño (LLM)](https://www.ibm.com/es-es/think/topics/open-source-llms). Disponibles en bibliotecas basadas en Python y Javascript, las herramientas y API de LangChain simplifican el proceso de creación de aplicaciones impulsadas por LLM, como [chatbots](https://www.ibm.com/es-es/topics/chatbots) y [agentes [...] LangChain es esencialmente una biblioteca de abstracciones para Python y Javascript, que representa los pasos y conceptos comunes necesarios para trabajar con modelos de lenguaje. Estos componentes modulares, como las funciones y las clases de objetos, sirven como bloques de construcción de los programas de IA generativa. Se pueden \"*encadenar*\" entre sí para crear aplicaciones, minimizando la cantidad de código y la comprensión precisa necesarios para ejecutar tareas complejas de PLN. Aunque [...] Descubra ideas y noticias de expertos sobre IA, nube y mucho más en el boletín semanal Think.\\n\\n## ¿Cómo funciona LangChain?\\n\\nEl núcleo de LangChain es un entorno de desarrollo que racionaliza la programación de aplicaciones LLM mediante el uso de\\xa0*abstracción*: la simplificación del código representando uno o más procesos complejos como un componente con nombre que encapsula todos sus pasos constituyentes.',\n",
       "  'score': 0.94339466},\n",
       " {'title': '¿Qué es LangChain? - IBM',\n",
       "  'url': 'https://www.ibm.com/mx-es/think/topics/langchain',\n",
       "  'content': 'LangChain es un marco de orquestación de código abierto para desarrollar aplicaciones con [modelos de lenguaje de gran tamaño (LLM)](https://www.ibm.com/mx-es/think/topics/open-source-llms). Proporciona herramientas en Python y JavaScript para integrar LLMs, bases de datos y APIs, facilitando la creación de [chatbots](https://www.ibm.com/mx-es/topics/chatbots),[agentes virtuales](https://www.ibm.com/mx-es/topics/virtual-agent) y sistemas de generación de texto. [...] LangChain es esencialmente una biblioteca de abstracciones para Python y Javascript, que representa los pasos y conceptos comunes necesarios para trabajar con modelos lingüísticos. Estos componentes modulares, como las funciones y las clases de objetos, sirven como bloques de construcción de los programas de IA generativa. Se pueden \"_encadenar_ \" entre sí para crear aplicaciones, minimizando la cantidad de código y la comprensión precisa necesarios para ejecutar tareas complejas de PLN. Aunque [...] [Las herramientas de LangChain](https://python.langchain.com/v0.2/docs/integrations/tools/)(enlace externo a ibm.com) son un conjunto de funciones que permiten a los agentes de LangChain interactuar con información del mundo real con el fin de ampliar o mejorar los servicios que puede proporcionar. Algunos ejemplos de herramientas destacadas de LangChain son:',\n",
       "  'score': 0.9405774},\n",
       " {'title': 'Introducción a LangChain y sus capacidades - OpenWebinars',\n",
       "  'url': 'https://openwebinars.net/blog/introduccion-langchain/',\n",
       "  'content': 'Es aquÃ\\xad donde LangChain entra en juego como un marco de trabajo que democratiza el acceso a los LLMs y permite a una amplia gama de usuarios crear aplicaciones inteligentes sin necesidad de profundos conocimientos en inteligencia artificial y programaciÃ³n. LangChain es un marco de trabajo de cÃ³digo abierto diseÃ±ado para facilitar la creaciÃ³n de aplicaciones basadas en LLMs. Proporciona una serie de herramientas y abstracciones que simplifican el proceso de desarrollo, permitiendo a los usuarios enfocarse en la lÃ³gica de negocio de sus aplicaciones sin tener que lidiar con los detalles tÃ©cnicos subyacentes de los LLMs. Un desarrollador puede utilizar LangChain para crear un chatbot que responda a preguntas sobre productos especÃ\\xadficos, integrando el modelo de lenguaje con una base de datos de productos de la empresa para proporcionar respuestas precisas y actualizadas.',\n",
       "  'score': 0.93468803},\n",
       " {'title': 'LangChain para Dummies: Guía Completa desde la Instalación ...',\n",
       "  'url': 'https://devjaime.medium.com/langchain-para-dummies-gu%C3%ADa-completa-desde-la-instalaci%C3%B3n-hasta-su-utilizaci%C3%B3n-8dc3df92f048',\n",
       "  'content': 'LangChain es una biblioteca de Python diseñada para facilitar la integración de modelos de lenguaje en aplicaciones. Permite a los',\n",
       "  'score': 0.9322132}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "searchTavily = TavilySearchResults()\n",
    "searchTavily.invoke(\"Que es LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90b245ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de herramientas\n",
    "tools = [wiki_tool, searchTavily]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122ff4a",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75367d9d",
   "metadata": {},
   "source": [
    "Son agentes de software autnomas que interactuan y responder dinamicamente con los usuarios y el entorno\n",
    "- Capaces dde realizar acciones\n",
    "- Utilizan y orquestan chains\n",
    "- Mantiene contexto y memoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c2556",
   "metadata": {},
   "source": [
    "HUB: Almacen de promts de la comunidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40f97803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Socius\\Desktop\\Langchain\\langchain practica\\.venv\\Lib\\site-packages\\langsmith\\client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "promt.messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b818a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHola! ¿En qué puedo ayudarte hoy?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hola!', 'output': 'Hola! ¿En qué puedo ayudarte hoy?\\n'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Hola!\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'LangChain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "\n",
      "Page: Intelligent agent\n",
      "Summary: In artificial intelligence, an intelligent agent is an entity that perceives its environment, takes actions autonomously to achieve goals, and may improve its performance through machine learning or by acquiring knowledge. Leading AI textbooks define artificial intelligence as the \"study and design of intelligent agents,\" emphasizing that goal-directed behavior is central to intelligence.\n",
      "A specialized subset of intelligent agents, agentic AI (also known as an AI agent or simply agent), expands this concept by proactively pursuing goals, making decisions, and taking actions over extended periods, thereby exemplifying a novel form of digital agency.\n",
      "Intelligent agents can range from simple to highly complex. A basic thermostat or control system is considered an intelligent agent, as is a human being, or any other system that meets the same criteria—such as a firm, a state, or a biome.\n",
      "Intelligent agents operate based on an objective function, which encapsulates their goals. They are designed to create and execute plans that maximize the expected value of this function upon completion. For example, a reinforcement learning agent has a reward function, which allows programmers to shape its desired behavior. Similarly, an evolutionary algorithm's behavior is guided by a fitness function.\n",
      "Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, and the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations.\n",
      "Intelligent agents are often described schematically as abstract functional systems similar to computer programs. To distinguish theoretical models from real-world implementations, abstract descriptions of intelligent agents are called abstract intelligent agents. Intelligent agents are also closely related to software agents—autonomous computer programs that carry out tasks on behalf of users. They are also referred to using a term borrowed from economics: a \"rational agent\".\n",
      "\n",
      "\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) models like large language models (LLMs) integrate and share data with external tools, systems, and data sources. Technology writers have dubbed MCP “the USB-C of AI apps”, underscoring its goal of serving as a universal connector between language-model agents and external software. Designed to standardize context exchange between AI assistants and software environments, MCP provides a model-agnostic universal interface for reading files, executing functions, and handling contextual prompts. It was officially announced and open-sourced by Anthropic in November 2024, and was adopted by major AI providers including OpenAI and Google DeepMind.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mLangChain es un marco de software que facilita la integración de modelos de lenguaje grande (LLM) en aplicaciones. Sus casos de uso incluyen análisis y resumen de documentos, chatbots y análisis de código.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Quiero aprender sobre LangChain.',\n",
       " 'output': 'LangChain es un marco de software que facilita la integración de modelos de lenguaje grande (LLM) en aplicaciones. Sus casos de uso incluyen análisis y resumen de documentos, chatbots y análisis de código.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando els ervicio de wikipedia\n",
    "agent_executor.invoke({\"input\": \"Quiero aprender sobre LangChain.\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbf1304b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'temperatura en buenos aires argentina'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'title': 'Previsión meteorológica de tres días para Buenos Aires ...', 'url': 'https://www.accuweather.com/es/ar/buenos-aires/7894/weather-forecast/7894', 'content': 'Temperatura. Previsión por horas. 13 57°. rain drop 0 % · 14 60°. rain ... Internacional América del Sur Argentina Ciudad Autónoma de Buenos Aires Buenos Aires', 'score': 0.80070794}, {'title': 'Pronóstico del tiempo por hora para Buenos Aires, Argentina', 'url': 'https://weather.com/es-US/tiempo/horario/l/eb21b6c30fe7eef7bdb5ae103d0669ffbb96ef1e33a2564bf01c340aca0248ed?par=samsung_widget', 'content': 'Pronóstico por horaBuenos Aires, Argentina • A partir de las 7:41 p.m. GMT-03:00 · 1 am. 54°. 24%. Nublado. Sensación térmica54° · 2 am. 54°. 24%. Nublado.', 'score': 0.75421005}, {'title': 'Tiempo actual en Buenos Aires, Ciudad Autónoma de ...', 'url': 'https://www.accuweather.com/es/ar/buenos-aires/7894/current-weather/7894', 'content': 'El tiempo ahora ; 54°F · Nublado ; RealFeel® 53°. Fresco. RealFeel Shade™ 53°. Fresco.', 'score': 0.72254705}, {'title': 'Clima en Buenos Aires hoy y pronóstico del tiempo a 14 días', 'url': 'https://www.clima.com/argentina/buenos-aires/buenos-aires', 'content': 'Temp. media: 11ºC · Temp. máx media: 15ºC · Temp. min media: 7ºC · Días de lluvia: 5 días · Acum. de lluvia: 47 mm · Viento medio: 14 km/h.', 'score': 0.6811549}, {'title': 'Tiempo en Buenos Aires. Clima a 14 días', 'url': 'https://www.meteored.com.ar/tiempo-en_Buenos+Aires-America+Sur-Argentina-Ciudad+Autonoma+de+Buenos+Aires-SABE-1-13584.html', 'content': '|  | | * Lluvia  Lluvia  **0% 0 mm** * Humedad  Humedad **68%** * Punto de rocío  Punto de rocío  **8 °C** * Nubosidad  Nubosidad **1%**  * Sensación Térmica  Sensación Térmica  **13 °C** * Visibilidad  Visibilidad **45 km** * Viento  Viento - Medio **7 km/h** * Presión  Presión  **1019 hPa**  * Niebla  Niebla **No** * Viento - Rachas  Viento - Rachas  **13 km/h** * Cota Nieve  Cota Nieve **3300 m** | | | | | |  | [...] |  | | * Lluvia  Lluvia  **0% 0 mm** * Humedad  Humedad **67%** * Punto de rocío  Punto de rocío  **8 °C** * Nubosidad  Nubosidad **1%**  * Sensación Térmica  Sensación Térmica  **14 °C** * Visibilidad  Visibilidad **45 km** * Viento  Viento - Medio **5 km/h** * Presión  Presión  **1018 hPa**  * Niebla  Niebla **No** * Viento - Rachas  Viento - Rachas  **19 km/h** * Cota Nieve  Cota Nieve **3300 m** | | | | | |  | [...] |  | | * Lluvia  Lluvia  **0% 0 mm** * Humedad  Humedad **63%** * Punto de rocío  Punto de rocío  **8 °C** * Nubosidad  Nubosidad **3%**  * Sensación Térmica  Sensación Térmica  **15 °C** * Visibilidad  Visibilidad **45 km** * Viento  Viento - Medio **6 km/h** * Presión  Presión  **1018 hPa**  * Niebla  Niebla **No** * Viento - Rachas  Viento - Rachas  **19 km/h** * Cota Nieve  Cota Nieve **3300 m** | | | | | |  |', 'score': 0.6033015}]\u001b[0m\u001b[32;1m\u001b[1;3mLa temperatura en Buenos Aires, Argentina es de 54°F (12°C). La sensación térmica es de 53°F (11.6°C).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Puedes usar la herramienta tavily para buscar cual es la temperatura en buenos aires argentina?',\n",
       " 'output': 'La temperatura en Buenos Aires, Argentina es de 54°F (12°C). La sensación térmica es de 53°F (11.6°C).'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usando el servicio de search\n",
    "agent_executor.invoke({\"input\": \"Puedes usar la herramienta tavily para buscar cual es la temperatura en buenos aires argentina?\",})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7594800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3199020f",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8949c",
   "metadata": {},
   "source": [
    "RAG: Retrieval Augmented Generation\n",
    "Componentes:\n",
    "- chunks: fragmentos de texto en los que se divide el archivo a procesar\n",
    "- embeddings: representacion numerica de lo que contiene cada chunk\n",
    "- consulta: tambien se vuelve una representacion numerica\n",
    "- retrieval: la consulta se compara con los embeddings y se obtienen los chunks para relevantes\n",
    "\n",
    "Doc gemini embeddings model: https://ai.google.dev/gemini-api/docs/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797a69c",
   "metadata": {},
   "source": [
    "**Primer paso - Preparar los datos**\n",
    "- generar chunks\n",
    "- generar embebes y almacenarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc61f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Define the directory containing the text file and the persistent directory\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.join(current_dir, \"utils\", \"files\", \"odyssey.txt\")\n",
    "persistent_directory = os.path.join(current_dir, \"utils\", \"db\", \"chroma_db\")\n",
    "\n",
    "# Check if the Chroma vector store already exists\n",
    "if not os.path.exists(persistent_directory):\n",
    "    print(\"Persistent directory does not exist. Initializing vector store...\")\n",
    "\n",
    "    # Ensure the text file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"The file {file_path} does not exist. Please check the path.\"\n",
    "        )\n",
    "\n",
    "    # Read the text content from the file\n",
    "    loader = TextLoader(file_path, encoding='utf-8')\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split the document into chunks\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Display information about the split documents\n",
    "    print(\"\\n--- Document Chunks Information ---\")\n",
    "    print(f\"Number of document chunks: {len(docs)}\")\n",
    "    print(f\"Sample chunk:\\n{docs[0].page_content}\\n\")\n",
    "\n",
    "    # Create embeddings\n",
    "    print(\"\\n--- Creating embeddings ---\")\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"text-embedding-004\"\n",
    "    )  # Update to a valid embedding model if needed\n",
    "    print(\"\\n--- Finished creating embeddings ---\")\n",
    "\n",
    "    # Create the vector store and persist it automatically\n",
    "    print(\"\\n--- Creating vector store ---\")\n",
    "    db = Chroma.from_documents(\n",
    "        docs, embeddings, persist_directory=persistent_directory)\n",
    "    print(\"\\n--- Finished creating vector store ---\")\n",
    "\n",
    "else:\n",
    "    print(\"Vector store already exists. No need to initialize.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1369684",
   "metadata": {},
   "source": [
    "# Ecosistema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079eed49",
   "metadata": {},
   "source": [
    "## LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc38a2a",
   "metadata": {},
   "source": [
    "**LangGraph**\n",
    "Es una biblioteca para construir app multifactor y con estado utilizando llm\n",
    "- Puede cordinar multiples chain o agents a travea sw multiples etpadas\n",
    "- Puede implementar comportamientos, tomar decisiones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e681258d",
   "metadata": {},
   "source": [
    "## LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc97ee",
   "metadata": {},
   "source": [
    "**LangSmith**: Plataforma unificada para depurar, probar y monitorear aplicaciones de modelos de lenguejas y agentes inteligentes\n",
    "- gratis para un unico usuario\n",
    "- https://www.langchain.com/pricing-langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f625f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34f96597",
   "metadata": {},
   "source": [
    "## Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d654fb3",
   "metadata": {},
   "source": [
    "**Hub** Prompts de la comunidad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda1c00",
   "metadata": {},
   "source": [
    "## LangServe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6acc15",
   "metadata": {},
   "source": [
    "**LangServe**: Facilita el despliegue y mantenimiento de app, convierte apps de ml en servidores API\n",
    "- construido con FastAPI\n",
    "- Se registran todas las entradas y salidas del servidor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d89f9",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1df81",
   "metadata": {},
   "source": [
    "## Antrophic Claude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0f64c",
   "metadata": {},
   "source": [
    "Anthropic models: \n",
    "- https://docs.anthropic.com/en/docs/models-overview \n",
    "- Pago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ae9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-opus-latest\")\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = promt | model\n",
    "chain.invoke({\"input\": \"Tell me a funny joke about Python.\"}).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacd1c5",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb66f00c",
   "metadata": {},
   "source": [
    "- Pago\n",
    "- Chat Model Documents: https://python.langchain.com/v0.2/docs/integrations/chat/\n",
    "- OpenAI Chat Model Documents: https://python.langchain.com/v0.2/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30603cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = promt | model\n",
    "chain.invoke({\"input\": \"Tell me a funny joke about Python.\"}).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee257b84",
   "metadata": {},
   "source": [
    "## Google - Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25756e56",
   "metadata": {},
   "source": [
    "- Gratuito con limitaciones \n",
    "- https://console.cloud.google.com/gen-app-builder/engines\n",
    "- https://ai.google.dev/gemini-api/docs/models/gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "32f05d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the Python say goodbye to the C++ programmer?\\n\\nBecause he didn't want to get bitten by a class!\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "promt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "chain = promt | llm\n",
    "chain.invoke({\"input\": \"Tell me a funny joke about Python.\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0fb2c",
   "metadata": {},
   "source": [
    "## IBM Granite, Flan-T5, Mixtral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f153adf",
   "metadata": {},
   "source": [
    "- paquete Python langchain-ibm. \n",
    "- Clases como WatsonxLLM y ChatWatsonx te permiten incorporar los modelos fundacionales de IBM (como los modelos Granite, Flan-T5, Mixtral, etc.) \n",
    "- Modelos de Embeddings: WatsonxEmbeddings te permite generar embeddings de texto usando los modelos de IBM, lo cual es crucial para aplicaciones de RAG (Generación Aumentada por Recuperación) y búsqueda semántica.\n",
    "Rerankers: WatsonxRerank ofrece capacidades para reordenar los resultados de búsqueda, mejorando la relevancia en los flujos de trabajo de RAG.\n",
    "- Toolkits: WatsonxToolkit proporciona un conjunto de herramientas diseñadas específicamente para interactuar con los servicios de watsonx dentro de los agentes de LangChain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
